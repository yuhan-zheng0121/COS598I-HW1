{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "346a1ac8-cea4-4153-bd46-c65cb76532eb",
   "metadata": {},
   "source": [
    "source: https://archive.ics.uci.edu/dataset/891/cdc+diabetes+health+indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff0148eb-bf30-458a-afca-ba3a3dfd968e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please uncomment the bellow command if you did not install ucimlrepo before\n",
    "#pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "218f074f-87b9-4033-834a-910dd7acaa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict, RepeatedStratifiedKFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42a9fc8-4c7c-43e5-8137-1b757f1a71b4",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fec71d56-bdfa-45da-b17a-4a8acab9a708",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    # Load the dataset\n",
    "    cdc_diabetes_health_indicators = fetch_ucirepo(id=891) \n",
    "\n",
    "    # Define categorical and numerical features\n",
    "    categorical_features = ['HighBP', 'HighChol','CholCheck','Smoker','Stroke','HeartDiseaseorAttack',\n",
    "                            'PhysActivity','Fruits','Veggies','HvyAlcoholConsump','AnyHealthcare',\n",
    "                            'NoDocbcCost','GenHlth','DiffWalk','Sex','Age','Education','Income']\n",
    "    numerical_features = ['BMI','MentHlth','PhysHlth',]\n",
    "\n",
    "    # Get features and target variable\n",
    "    X = cdc_diabetes_health_indicators.data.features\n",
    "    y = cdc_diabetes_health_indicators.data.targets['Diabetes_binary'] \n",
    "\n",
    "    # Preprocessing: One-hot encoding for categorical variables and scaling for numerical variables\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numerical_features),\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "        ])\n",
    "\n",
    "    # Split the dataset into training and testing sets with a fixed random state for reproducibility\n",
    "    X_train_full, X_test_full, y_train, y_test, gender_train, gender_test = train_test_split(\n",
    "        X, y, cdc_diabetes_health_indicators.data.features['Sex'], test_size=0.2, random_state=42\n",
    "    )\n",
    "    # Apply preprocessing to training and testing set separately\n",
    "    X_train_processed = preprocessor.fit_transform(X_train_full)\n",
    "    X_test_processed = preprocessor.transform(X_test_full)\n",
    "\n",
    "    # Return processed training and testing sets along with gender attributes\n",
    "    return X_train_processed, X_test_processed, y_train, y_test, gender_train.values, gender_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17b27f41-f1e5-4207-b636-137f34451291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_confusion_matrix(df):\n",
    "    if df['y_true'] == df['y_pred'] == 1:\n",
    "        return 'TP'\n",
    "    elif df['y_pred'] == 1 and df['y_true'] != df['y_pred']:\n",
    "        return 'FP'\n",
    "    elif df['y_true'] == df['y_pred'] == 0:\n",
    "        return 'TN'\n",
    "    else:\n",
    "        return 'FN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be0e43e4-2f58-4737-8f0e-d6c07e988f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess and load the data\n",
    "X_train, X_test, y_train, y_test, gender_train, gender_test = load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99af9e8c-5a5a-4ce2-8583-2c3fcdbc9fb5",
   "metadata": {},
   "source": [
    "## Train Model and Generate Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d1760f-c9f1-4454-a059-695aa9e41cbe",
   "metadata": {},
   "source": [
    "### Select Model Based on Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5251fbe2-9d72-4716-b39e-57e6fe3efeee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8676087984862819 \n",
      "AUC: 0.8288682758066404 \n",
      "f1: 0.2510870777121195\n"
     ]
    }
   ],
   "source": [
    "# try logistic regression\n",
    "model1 = LogisticRegression(max_iter=10000, random_state=0)\n",
    "\n",
    "# Train the Logistic Regression model\n",
    "model1.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred1 = model1.predict(X_test)\n",
    "y_pred_proba1 = model1.predict_proba(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy1 = accuracy_score(y_test, y_pred1)\n",
    "auc1 = roc_auc_score(y_test, y_pred_proba1[:, 1])\n",
    "f1_1 = f1_score(y_test, y_pred1)\n",
    "\n",
    "print('Accuracy:', accuracy1, '\\nAUC:', auc1, '\\nf1:', f1_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a05e0cb4-d49e-4366-ad54-c186e4a4197c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8676876379690949 \n",
      "AUC: 0.8329001174326579 \n",
      "f1: 0.23323814962878356\n"
     ]
    }
   ],
   "source": [
    "# try nn\n",
    "model2 = MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(21,), random_state=1, max_iter=100)\n",
    "\n",
    "# Train the Logistic Regression model\n",
    "model2.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred2 = model2.predict(X_test)\n",
    "y_pred_proba2 = model2.predict_proba(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy2 = accuracy_score(y_test, y_pred2)\n",
    "auc2 = roc_auc_score(y_test, y_pred_proba2[:, 1])\n",
    "f1_2 = f1_score(y_test, y_pred2)\n",
    "\n",
    "print('Accuracy:', accuracy2, '\\nAUC:', auc2, '\\nf1:', f1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee29521f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try svm, running unexpected long, give up with this model\n",
    "# from sklearn import svm\n",
    "\n",
    "# clf2 = svm.SVC()\n",
    "# clf2.fit(X_train, y_train)\n",
    "\n",
    "# y_pred2 = clf2.predict(X_test)\n",
    "# y_pred_proba2 = clf2.predict_proba(X_test)[:, 1]\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# print('Accuracy:', accuracy, '\\nAUC:', auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ffe389",
   "metadata": {},
   "source": [
    "### Train Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4855fad-564b-44f7-9078-0bbe302e726d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred1\n",
    "y_pred_proba = y_pred_proba1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2d83970-94b6-4ebd-88b3-78068e179577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>confusion_matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>219620</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132821</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151862</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139717</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239235</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sex  y_true  y_pred confusion_matrix\n",
       "219620    0       0       0               TN\n",
       "132821    0       0       0               TN\n",
       "151862    1       0       0               TN\n",
       "139717    1       0       0               TN\n",
       "239235    0       0       0               TN"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Female = 0 and Male = 1\n",
    "fair_df = pd.DataFrame({'sex': gender_test, 'y_true': y_test, 'y_pred': y_pred})\n",
    "fair_df['confusion_matrix'] = fair_df[['y_true','y_pred']].apply(determine_confusion_matrix, axis=1)\n",
    "fair_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b49c862-f0cc-4ac1-bfd5-3474a181aab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.94368063, 0.05631937],\n",
       "       [0.77816319, 0.22183681],\n",
       "       [0.99647526, 0.00352474],\n",
       "       ...,\n",
       "       [0.91102181, 0.08897819],\n",
       "       [0.8648969 , 0.1351031 ],\n",
       "       [0.9863914 , 0.0136086 ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15b35201-c990-41e9-a8e7-189bdebdf0f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sex\n",
       "0    28412\n",
       "1    22324\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0 stand for female and 1 is male\n",
    "fair_df['sex'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c5649a-647d-457b-85a3-ea5d15006b7d",
   "metadata": {},
   "source": [
    "## Fairness Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c691447-0c41-4d6d-b116-ec72af1e1c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6903f98d-f05e-4f21-bdf9-2418f7cc4d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistical_parity(df):\n",
    "    female_positive = df[(df['sex'] == 0) & (df['y_pred'] == 1)].shape[0]\n",
    "    female_positive_prob = female_positive / (df[(df['sex'] == 0)].shape[0])\n",
    "    \n",
    "    male_positive = df[(df['sex'] == 1) & (df['y_pred'] == 1)].shape[0]\n",
    "    male_positive_prob = male_positive / (df[(df['sex'] == 1)].shape[0])\n",
    "\n",
    "    print('Female Probability of Positive Predictions: %.3f' % female_positive_prob)\n",
    "    print('Male Probability of Positive Predictions: %.3f' % male_positive_prob)\n",
    "    \n",
    "    abs_difference = abs(female_positive_prob - male_positive_prob)\n",
    "    print('Achieves Statistical Parity: %r' % (abs_difference < threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de79c959-16b5-4178-b962-eec1f1c5e6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictive_parity(df):\n",
    "    female_TP = df[(df['sex'] == 0) & (df['confusion_matrix'] == 'TP')].shape[0]\n",
    "    PPV_female = female_TP / (df[(df['sex'] == 0) & (df['y_pred'] == 1)].shape[0])\n",
    "    \n",
    "    male_TP = df[(df['sex'] == 1) & (df['confusion_matrix'] == 'TP')].shape[0]\n",
    "    PPV_male = male_TP / (df[(df['sex'] == 1) & (df['y_pred'] == 1)].shape[0])\n",
    "\n",
    "    print('Female Probability of True Positive Predictions: %.3f' % PPV_female)\n",
    "    print('Male Probability of True Positive Predictions: %.3f' % PPV_male)\n",
    "    \n",
    "    abs_difference = abs(PPV_female - PPV_male)\n",
    "    print('Achieves Predictive Parity: %r' % (abs_difference < threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3bcc00d-7793-4991-8929-bcc303d76957",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equalized_odds(df):\n",
    "    # FNR = FN/(FN+TP) = FN/(all-positive-true-label)\n",
    "    female_fn = df[(df['sex'] == 0) & (df['confusion_matrix'] == 'FN')].shape[0]\n",
    "    fnr_female = female_fn / (df[(df['sex'] == 0) & (df['y_true'] == 1)].shape[0])\n",
    "    male_fn = df[(df['sex'] == 1) & (df['confusion_matrix'] == 'FN')].shape[0]\n",
    "    fnr_male = male_fn / (df[(df['sex'] == 1) & (df['y_true'] == 1)].shape[0])\n",
    "    \n",
    "    # FPR = FP/(FP+TN) = FN/(all-negative-true-label)\n",
    "    female_fp = df[(df['sex'] == 0) & (df['confusion_matrix'] == 'FP')].shape[0]\n",
    "    fpr_female = female_fp / (df[(df['sex'] == 0) & (df['y_true'] == 0)].shape[0])\n",
    "    male_fp = df[(df['sex'] == 1) & (df['confusion_matrix'] == 'FP')].shape[0]\n",
    "    fpr_male = male_fp / (df[(df['sex'] == 1) & (df['y_true'] == 0)].shape[0])\n",
    "\n",
    "    print('Probability of Female with Diabetes Predicted No Diabetes: %.3f' % fnr_female)\n",
    "    print('Probability of Male with Diabetes Predicted No Diabetes: %.3f' % fnr_male)\n",
    "    \n",
    "    abs_difference_fnr = abs(fnr_female - fnr_male)\n",
    "    print('Achieves Equality of No Diabetes Prediction: %r' % (abs_difference_fnr < threshold))\n",
    "    \n",
    "    print('Probability of Female with No Diabetes Predicted Having Diabetes: %.3f' % fpr_female)\n",
    "    print('Probability of Male with No Diabetes Predicted Having Diabetes: %.3f' % fpr_male)\n",
    "    \n",
    "    abs_difference_fpr = abs(fnr_female - fnr_male)\n",
    "    print('Achieves Equality of Having Diabetes Prediction: %r' % (abs_difference_fpr < threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8462a21d-b449-4449-b5c2-d4b664d914b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_equality(df):\n",
    "    # Accuracy = (TP+TN)/all-samples\n",
    "    female_t = df[(df['sex'] == 0) & (df['confusion_matrix'].isin(['TP', 'TN']))].shape[0]\n",
    "    accuracy_female = female_t / (df[(df['sex'] == 0)].shape[0])\n",
    "    male_t = df[(df['sex'] == 1) & (df['confusion_matrix'].isin(['TP', 'TN']))].shape[0]\n",
    "    accuracy_male = male_t / (df[(df['sex'] == 1)].shape[0])\n",
    "    \n",
    "    print('Female Accuracy: %.3f' % accuracy_female)\n",
    "    print('Male Accuracy: %.3f' % accuracy_male)\n",
    "    \n",
    "    abs_difference = abs(accuracy_female - accuracy_male)\n",
    "    print('Equality of Accuracy: %r' % (abs_difference < threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c44e558-3bfb-4681-8d1b-bc85e33c8785",
   "metadata": {},
   "outputs": [],
   "source": [
    "def treatment_equality(df):    \n",
    "    female = df[(df['sex'] == 0)]\n",
    "    ratio_female = (female[female['confusion_matrix'] == 'FN'].shape[0] / \n",
    "        female[female['confusion_matrix'] == 'FP'].shape[0])\n",
    "\n",
    "    male = df[(df['sex'] == 1)]\n",
    "    ratio_male = (male[male['confusion_matrix'] == 'FN'].shape[0] / \n",
    "        male[male['confusion_matrix'] == 'FP'].shape[0])\n",
    "\n",
    "    print('Female Ratio of Errors: %.3f' % ratio_female)\n",
    "    print('Male Ratio of Errors: %.3f' % ratio_male)\n",
    "    \n",
    "    abs_difference = abs(ratio_female - ratio_male)\n",
    "    print('Achieves Treatment Equality: %r' % (abs_difference < threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d43a913-fe5a-46f3-91da-e23cf72f6e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Female Probability of Positive Predictions: 0.036\n",
      "Male Probability of Positive Predictions: 0.043\n",
      "Achieves Statistical Parity: False\n",
      "Female Probability of True Positive Predictions: 0.570\n",
      "Male Probability of True Positive Predictions: 0.572\n",
      "Achieves Predictive Parity: False\n",
      "Probability of Female with Diabetes Predicted No Diabetes: 0.842\n",
      "Probability of Male with Diabetes Predicted No Diabetes: 0.835\n",
      "Achieves Equality of No Diabetes Prediction: False\n",
      "Probability of Female with No Diabetes Predicted Having Diabetes: 0.018\n",
      "Probability of Male with No Diabetes Predicted Having Diabetes: 0.022\n",
      "Achieves Equality of Having Diabetes Prediction: False\n",
      "Female Accuracy: 0.876\n",
      "Male Accuracy: 0.857\n",
      "Equality of Accuracy: False\n",
      "Female Ratio of Errors: 7.092\n",
      "Male Ratio of Errors: 6.779\n",
      "Achieves Treatment Equality: False\n"
     ]
    }
   ],
   "source": [
    "statistical_parity(fair_df)\n",
    "predictive_parity(fair_df)\n",
    "equalized_odds(fair_df)\n",
    "accuracy_equality(fair_df)\n",
    "treatment_equality(fair_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8cf444-3048-4c54-87f2-e47ec29e5d11",
   "metadata": {},
   "source": [
    "## Mitigation through Post-Processiong"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51c8ff3-6aae-4bc9-810e-f10e8a022e97",
   "metadata": {},
   "source": [
    "On Fairness and Calibration: https://arxiv.org/pdf/1709.02012.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "036ecdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trivial_pred(df):\n",
    "    trivial_df = df.copy()\n",
    "    trivial_base_rate = df['y_true'].mean()\n",
    "    trivial_df['y_prob_1'] = trivial_base_rate\n",
    "    trivial_df['y_prob_0'] = 1.0 - trivial_df['y_prob_1']\n",
    "    trivial_df = reclassify(trivial_df)\n",
    "    \n",
    "    return trivial_df, trivial_base_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5937d060-9729-4bf5-8080-e13d60b2d889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reassign prediction based on the adjusted y_prob(args_max)\n",
    "def reclassify(df): \n",
    "    new_y_pred = []\n",
    "    for _, row in df.iterrows():\n",
    "        if row['y_prob_0'] >=  row['y_prob_1']:\n",
    "            new_y_pred.append(0)\n",
    "        else:\n",
    "            new_y_pred.append(1)\n",
    "    df['y_pred'] = new_y_pred \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32e703cc-3025-42c2-ba43-9e0748c23a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute fpr and fnr given y_probs and true labels\n",
    "def compute_errors(df):\n",
    "    df_copy = df.copy()\n",
    "    df_copy['confusion_matrix'] = df_copy[['y_true','y_pred']].apply(determine_confusion_matrix, axis=1)\n",
    "    fpr = df_copy[df_copy['confusion_matrix'] == 'FP'].shape[0]/df_copy[df_copy['y_true'] == 0].shape[0]\n",
    "    fnr = df_copy[df_copy['confusion_matrix'] == 'FN'].shape[0]/df_copy[df_copy['y_true'] == 1].shape[0]\n",
    "    return fpr, fnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9e176129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mix rate and calibrated\n",
    "def calibrate_eq_odds(g1, g2, fnr=1, fpr=1):\n",
    "    # create trivial classifier\n",
    "    g1_trivial, g1_trivial_base_rate = trivial_pred(g1)\n",
    "    g2_trivial, g2_trivial_base_rate = trivial_pred(g2)\n",
    "    \n",
    "    # compute generalized fpr and generalized fnr for all 4 sets of output\n",
    "    # g1_fp_cost = mean y_pred=1 prob for rows where y_true=0\n",
    "    g1_g_fp = g1.loc[g1['y_true'] == 0, 'y_prob_1'].mean() \n",
    "    g2_g_fp = g2.loc[g2['y_true'] == 0, 'y_prob_1'].mean()\n",
    "    g1_trivial_g_fp = g1_trivial.loc[g1_trivial['y_true'] == 0, 'y_prob_1'].mean()\n",
    "    g2_trivial_g_fp = g2_trivial.loc[g2_trivial['y_true'] == 0, 'y_prob_1'].mean()\n",
    "    \n",
    "    # g1_fn_cost = 1- mean y_pred=1 prob for rows where y_true=1\n",
    "    g1_g_fn = 1 - g1.loc[g1['y_true'] == 1, 'y_prob_1'].mean()\n",
    "    g2_g_fn = 1 - g2.loc[g2['y_true'] == 1, 'y_prob_1'].mean()\n",
    "    g1_trivial_g_fn = 1 - g1_trivial.loc[g1_trivial['y_true'] == 1, 'y_prob_1'].mean()\n",
    "    g2_trivial_g_fn = 1 - g2_trivial.loc[g2_trivial['y_true'] == 1, 'y_prob_1'].mean()\n",
    "\n",
    "    g1_base_rate = g1['y_true'].mean()\n",
    "    g2_base_rate = g2['y_true'].mean()\n",
    "\n",
    "    # calibrate by consider both rate\n",
    "    if fpr and fnr:\n",
    "        g1_cost = 1 / 2.0 * g1_g_fp * (1 - g1_base_rate) + 1 / 2.0 * g1_g_fn * g1_base_rate\n",
    "        g2_cost = 1 / 2.0 * g2_g_fp * (1 - g2_base_rate) + 1 / 2.0 * g2_g_fn * g2_base_rate\n",
    "        print(g1_cost, g2_cost)\n",
    "        g1_trivial_cost = (1 / 2.0 * g1_trivial_g_fp * (1 - g1_trivial_base_rate) \n",
    "                           + 1 / 2.0 * g1_trivial_g_fn * g1_trivial_base_rate)\n",
    "        g2_trivial_cost = (1 / 2.0 * g2_trivial_g_fp * (1 - g2_trivial_base_rate) \n",
    "                           + 1 / 2.0 * g2_trivial_g_fn * g2_trivial_base_rate)\n",
    "    # calibrate FP rate\n",
    "    elif fpr:\n",
    "        g1_cost = g1_g_fp\n",
    "        g2_cost = g2_g_fp\n",
    "        g1_trivial_cost = g1_trivial_g_fp\n",
    "        g2_trivial_cost = g2_trivial_g_fp\n",
    "    # calibrate FN rate\n",
    "    else:\n",
    "        g1_cost = g1_g_fn\n",
    "        g2_cost = g2_g_fn\n",
    "        g1_trivial_cost = g1_trivial_g_fn\n",
    "        g2_trivial_cost = g2_trivial_g_fn\n",
    "\n",
    "    g2_cost_more = g2_cost > g1_cost\n",
    "    g1_mix_rate = (g2_cost - g1_cost) / (g1_trivial_cost - g1_cost) if g2_cost_more else 0\n",
    "    g2_mix_rate = 0 if g2_cost_more else (g1_cost - g2_cost) / (g2_trivial_cost - g2_cost)\n",
    "    \n",
    "    # Randomly select mix_rate% of elements from the prediction\n",
    "    g1_copy = g1.copy(deep=True)\n",
    "    g1_random_indices = np.random.choice(g1_copy['y_prob_1'].index, \n",
    "                                         size=int(g1_mix_rate*g1_copy.shape[0]), replace=False)\n",
    "    g2_copy = g2.copy(deep=True)\n",
    "    g2_random_indices = np.random.choice(g2_copy['y_prob_1'].index, \n",
    "                                         size=int(g2_mix_rate*g2_copy.shape[0]), replace=False)\n",
    "    \n",
    "    # Set those to base_rate\n",
    "    g1_copy.loc[g1_random_indices, 'y_prob_1'] = g1_base_rate\n",
    "    g2_copy.loc[g2_random_indices, 'y_prob_1'] = g2_base_rate\n",
    "    g1_copy.loc[g1_random_indices, 'y_prob_0'] = 1 - g1_base_rate\n",
    "    g2_copy.loc[g2_random_indices, 'y_prob_0'] = 1 - g2_base_rate\n",
    "    \n",
    "    # reclassify\n",
    "    caibrated_g1 = reclassify(g1_copy)\n",
    "    caibrated_g2 = reclassify(g2_copy)\n",
    "    \n",
    "    # Update confusion matrix\n",
    "    caibrated_g1['confusion_matrix'] = caibrated_g1[['y_true','y_pred']].apply(determine_confusion_matrix, axis=1)\n",
    "    caibrated_g2['confusion_matrix'] = caibrated_g2[['y_true','y_pred']].apply(determine_confusion_matrix, axis=1)\n",
    "\n",
    "    \n",
    "    return caibrated_g1, caibrated_g2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1605191a-360e-4700-87ab-c9a09c33398c",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_processiong_df = pd.DataFrame({'sex': gender_test, 'y_true': y_test, 'y_pred': y_pred, \n",
    "                                    'y_prob_1': y_pred_proba[:, 1], 'y_prob_0': y_pred_proba[:, 0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0a9795aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "male_data = post_processiong_df[post_processiong_df['sex'] == 1]\n",
    "female_data = post_processiong_df[post_processiong_df['sex'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3a9c16e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09112231284032365 0.10493468441308659\n"
     ]
    }
   ],
   "source": [
    "calibrated_g1, calibrated_g2 = calibrate_eq_odds(female_data, male_data, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "14e735a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred\n",
      "0    28055\n",
      "1      357\n",
      "Name: count, dtype: int64 0.12959424212166823\n",
      "y_pred\n",
      "0    21364\n",
      "1      960\n",
      "Name: count, dtype: int64 0.1521268316742733\n"
     ]
    }
   ],
   "source": [
    "print(calibrated_g1['y_pred'].value_counts(), calibrated_g1['y_prob_1'].mean())\n",
    "print(calibrated_g2['y_pred'].value_counts(), calibrated_g2['y_prob_1'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6ebeb385",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrated = pd.concat([calibrated_g1, calibrated_g2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3dd91a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Female Probability of Positive Predictions: 0.013\n",
      "Male Probability of Positive Predictions: 0.043\n",
      "Achieves Statistical Parity: False\n",
      "Female Probability of True Positive Predictions: 0.594\n",
      "Male Probability of True Positive Predictions: 0.572\n",
      "Achieves Predictive Parity: False\n",
      "Probability of Female with Diabetes Predicted No Diabetes: 0.942\n",
      "Probability of Male with Diabetes Predicted No Diabetes: 0.835\n",
      "Achieves Equality of No Diabetes Prediction: False\n",
      "Probability of Female with No Diabetes Predicted Having Diabetes: 0.006\n",
      "Probability of Male with No Diabetes Predicted Having Diabetes: 0.022\n",
      "Achieves Equality of Having Diabetes Prediction: False\n",
      "Female Accuracy: 0.873\n",
      "Male Accuracy: 0.857\n",
      "Equality of Accuracy: False\n",
      "Female Ratio of Errors: 23.793\n",
      "Male Ratio of Errors: 6.779\n",
      "Achieves Treatment Equality: False\n"
     ]
    }
   ],
   "source": [
    "statistical_parity(calibrated)\n",
    "predictive_parity(calibrated)\n",
    "equalized_odds(calibrated)\n",
    "accuracy_equality(calibrated)\n",
    "treatment_equality(calibrated)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "COS520",
   "language": "python",
   "name": "cos520"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
