{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d42a9fc8-4c7c-43e5-8137-1b757f1a71b4",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346a1ac8-cea4-4153-bd46-c65cb76532eb",
   "metadata": {},
   "source": [
    "source: https://archive.ics.uci.edu/dataset/891/cdc+diabetes+health+indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff0148eb-bf30-458a-afca-ba3a3dfd968e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ucimlrepo\n",
      "  Downloading ucimlrepo-0.0.3-py3-none-any.whl.metadata (5.2 kB)\n",
      "Downloading ucimlrepo-0.0.3-py3-none-any.whl (7.0 kB)\n",
      "Installing collected packages: ucimlrepo\n",
      "Successfully installed ucimlrepo-0.0.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "218f074f-87b9-4033-834a-910dd7acaa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict, RepeatedStratifiedKFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fec71d56-bdfa-45da-b17a-4a8acab9a708",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    # Load the dataset\n",
    "    cdc_diabetes_health_indicators = fetch_ucirepo(id=891) \n",
    "\n",
    "    # Define categorical and numerical features\n",
    "    categorical_features = ['HighBP', 'HighChol','CholCheck','Smoker','Stroke','HeartDiseaseorAttack',\n",
    "                            'PhysActivity','Fruits','Veggies','HvyAlcoholConsump','AnyHealthcare','NoDocbcCost','GenHlth',\n",
    "                            'DiffWalk','Sex','Age','Education','Income']\n",
    "    numerical_features = ['BMI','MentHlth','PhysHlth',]\n",
    "\n",
    "    # Get features and target variable\n",
    "    X = cdc_diabetes_health_indicators.data.features\n",
    "    y = cdc_diabetes_health_indicators.data.targets['Diabetes_binary'] \n",
    "\n",
    "    # Preprocessing: One-hot encoding for categorical variables and scaling for numerical variables\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numerical_features),\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "        ])\n",
    "\n",
    "    # Split the dataset into training and testing sets with a fixed random state for reproducibility\n",
    "    X_train_full, X_test_full, y_train, y_test, gender_train, gender_test = train_test_split(X, y, \n",
    "                                                                                             cdc_diabetes_health_indicators.data.features['Sex'],\n",
    "                                                                                             test_size=0.2, random_state=42)\n",
    "    # Apply preprocessing to training and testing set separately\n",
    "    X_train_processed = preprocessor.fit_transform(X_train_full)\n",
    "    X_test_processed = preprocessor.transform(X_test_full)\n",
    "\n",
    "    # Return processed training and testing sets along with gender attributes\n",
    "    return X_train_processed, X_test_processed, y_train, y_test, gender_train.values, gender_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f22a21-81e1-40b1-88d3-a813fcbcd006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cdc_diabetes_health_indicators.metadata\n",
    "# cdc_diabetes_health_indicators.variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99af9e8c-5a5a-4ce2-8583-2c3fcdbc9fb5",
   "metadata": {},
   "source": [
    "## Train Model and Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8d4c7f79-ec9b-4d69-bd26-0c400213e671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict_model(X_train, X_test, y_train, weights=None):\n",
    "\n",
    "    # Initialize the Logistic Regression model\n",
    "    model = LogisticRegression(max_iter=10000, random_state=0)\n",
    "\n",
    "    # Train the Logistic Regression model\n",
    "    model.fit(X_train, y_train, sample_weight=weights)\n",
    "\n",
    "    # Predict on the testing set\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    return y_pred, y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "17b27f41-f1e5-4207-b636-137f34451291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_confusion_matrix(df):\n",
    "    if df['y_true'] == df['y_pred'] == 1:\n",
    "        return 'TP'\n",
    "    elif df['y_pred'] == 1 and df['y_true'] != df['y_pred']:\n",
    "        return 'FP'\n",
    "    elif df['y_true'] == df['y_pred'] == 0:\n",
    "        return 'TN'\n",
    "    else:\n",
    "        return 'FN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "be0e43e4-2f58-4737-8f0e-d6c07e988f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8676285083569851 \n",
      "AUC: 0.8288682104560867\n"
     ]
    }
   ],
   "source": [
    "# preprocess and load the data\n",
    "X_train, X_test, y_train, y_test, gender_train, gender_test = load_dataset()\n",
    "\n",
    "# train a model and obtain predictions on the test set\n",
    "y_pred, y_pred_proba = train_and_predict_model(X_train, X_test, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print('Accuracy:', accuracy, '\\nAUC:', auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "715db5b3-b063-466d-9e79-6776134e09cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(alpha=1e-05, hidden_layer_sizes=(21,), random_state=1,\n",
       "              solver=&#x27;lbfgs&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(alpha=1e-05, hidden_layer_sizes=(21,), random_state=1,\n",
       "              solver=&#x27;lbfgs&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(21,), random_state=1,\n",
       "              solver='lbfgs')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try neural net\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(21,), random_state=1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred1 = clf.predict(X_test)\n",
    "y_pred_proba1 = clf.predict_proba(X_test)[:, 1]\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print('Accuracy:', accuracy, '\\nAUC:', auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed72061-0011-4a7f-8c42-3cc343da0525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try svm\n",
    "from sklearn import svm\n",
    "\n",
    "clf2 = svm.SVC()\n",
    "clf2.fit(X_train, y_train)\n",
    "\n",
    "y_pred2 = clf2.predict(X_test)\n",
    "y_pred_proba2 = clf2.predict_proba(X_test)[:, 1]\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print('Accuracy:', accuracy, '\\nAUC:', auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d2d83970-94b6-4ebd-88b3-78068e179577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>confusion_matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>219620</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132821</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151862</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139717</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239235</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sex  y_true  y_pred confusion_matrix\n",
       "219620    0       0       0               TN\n",
       "132821    0       0       0               TN\n",
       "151862    1       0       0               TN\n",
       "139717    1       0       0               TN\n",
       "239235    0       0       0               TN"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Female = 1 and Male = 0\n",
    "fair_df = pd.DataFrame({'sex': gender_test, 'y_true': y_test, 'y_pred': y_pred})\n",
    "fair_df['confusion_matrix'] = fair_df[['y_true','y_pred']].apply(determine_confusion_matrix, axis=1)\n",
    "fair_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b35201-c990-41e9-a8e7-189bdebdf0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 stand for female and 0 is male\n",
    "fair_df['sex'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c5649a-647d-457b-85a3-ea5d15006b7d",
   "metadata": {},
   "source": [
    "## Fairness Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0c691447-0c41-4d6d-b116-ec72af1e1c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6903f98d-f05e-4f21-bdf9-2418f7cc4d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistical_parity(df):\n",
    "    \"\"\"\n",
    "    TODO: Add your code here\n",
    "    \"\"\"\n",
    "    female_positive = df[(df['sex'] == 1) & (df['y_pred'] == 1)].shape[0]\n",
    "    female_positive_prob = female_positive / (df[(df['sex'] == 1)].shape[0])\n",
    "    \n",
    "    male_positive = df[(df['sex'] == 0) & (df['y_pred'] == 1)].shape[0]\n",
    "    male_positive_prob = male_positive / (df[(df['sex'] == 0)].shape[0])\n",
    "\n",
    "    print('Female Probability of Positive Predictions: %.3f' % female_positive_prob)\n",
    "    print('Male Probability of Positive Predictions: %.3f' % male_positive_prob)\n",
    "    \n",
    "    abs_difference = abs(female_positive_prob - male_positive_prob)\n",
    "    print('Achieves Statistical Parity: %r' % (abs_difference < threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "de79c959-16b5-4178-b962-eec1f1c5e6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictive_parity(df):\n",
    "    \"\"\"\n",
    "    TODO: Add your code here\n",
    "    \"\"\"\n",
    "    female_TP = df[(df['sex'] == 1) & (df['confusion_matrix'] == 'TP')].shape[0]\n",
    "    PPV_female = female_TP / (df[(df['sex'] == 1) & (df['y_pred'] == 1)].shape[0])\n",
    "    \n",
    "    male_TP = df[(df['sex'] == 0) & (df['confusion_matrix'] == 'TP')].shape[0]\n",
    "    PPV_male = male_TP / (df[(df['sex'] == 0) & (df['y_pred'] == 1)].shape[0])\n",
    "\n",
    "    print('Female Probability of True Positive Predictions: %.3f' % PPV_female)\n",
    "    print('Male Probability of True Positive Predictions: %.3f' % PPV_male)\n",
    "    \n",
    "    abs_difference = abs(PPV_female - PPV_male)\n",
    "    print('Achieves Statistical Parity: %r' % (abs_difference < threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c3bcc00d-7793-4991-8929-bcc303d76957",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equalized_odds(df):\n",
    "    \"\"\"\n",
    "    TODO: Add your code here\n",
    "    \"\"\"\n",
    "    # FNR = FN/(FN+TP) = FN/(all-positive-true-label)\n",
    "    female_fn = df[(df['sex'] == 1) & (df['confusion_matrix'] == 'FN')].shape[0]\n",
    "    fnr_female = female_fn / (df[(df['sex'] == 1) & (df['y_true'] == 1)].shape[0])\n",
    "    male_fn = df[(df['sex'] == 0) & (df['confusion_matrix'] == 'FN')].shape[0]\n",
    "    fnr_male = male_fn / (df[(df['sex'] == 0) & (df['y_true'] == 1)].shape[0])\n",
    "    \n",
    "    # FPR = FP/(FP+TN) = FN/(all-negative-true-label)\n",
    "    female_fp = df[(df['sex'] == 1) & (df['confusion_matrix'] == 'FP')].shape[0]\n",
    "    fpr_female = female_fp / (df[(df['sex'] == 1) & (df['y_true'] == 0)].shape[0])\n",
    "    male_fp = df[(df['sex'] == 0) & (df['confusion_matrix'] == 'FP')].shape[0]\n",
    "    fpr_male = male_fp / (df[(df['sex'] == 0) & (df['y_true'] == 0)].shape[0])\n",
    "\n",
    "    print('Probability of Credit-Worthy Female Predicted Not Credit-Worthy: %.3f' % fnr_female)\n",
    "    print('Probability of Credit-Worthy Male Predicted Not Credit-Worthy: %.3f' % fnr_male)\n",
    "    \n",
    "    abs_difference_fnr = abs(fnr_female - fnr_male)\n",
    "    print('Achieves Equality of Non Credit Worthy Prediction: %r' % (abs_difference_fnr < threshold))\n",
    "    \n",
    "    print('Probability of Non Credit-Worthy Female Predicted Credit-Worthy: %.3f' % fpr_female)\n",
    "    print('Probability of Non Credit-Worthy Male Predicted Credit-Worthy: %.3f' % fpr_male)\n",
    "    \n",
    "    abs_difference_fpr = abs(fnr_female - fnr_male)\n",
    "    print('Achieves Equality of Credit Worthy Prediction: %r' % (abs_difference_fpr < threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8462a21d-b449-4449-b5c2-d4b664d914b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_equality(df):\n",
    "    \"\"\"\n",
    "    TODO: Add your code here\n",
    "    \"\"\"\n",
    "\n",
    "    # Accuracy = (TP+TN)/all-samples\n",
    "    female_t = df[(df['sex'] == 1) & (df['confusion_matrix'].isin(['TP', 'TN']))].shape[0]\n",
    "    accuracy_female = female_t / (df[(df['sex'] == 1)].shape[0])\n",
    "    male_t = df[(df['sex'] == 0) & (df['confusion_matrix'].isin(['TP', 'TN']))].shape[0]\n",
    "    accuracy_male = male_t / (df[(df['sex'] == 0)].shape[0])\n",
    "    \n",
    "    print('Female Accuracy: %.3f' % accuracy_female)\n",
    "    print('Male Accuracy: %.3f' % accuracy_male)\n",
    "    \n",
    "    abs_difference = abs(accuracy_female - accuracy_male)\n",
    "    print('Equality of Accuracy: %r' % (abs_difference < threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6c44e558-3bfb-4681-8d1b-bc85e33c8785",
   "metadata": {},
   "outputs": [],
   "source": [
    "def treatment_equality(df):\n",
    "    \"\"\"\n",
    "    TODO: Add your code here\n",
    "    \"\"\"\n",
    "    \n",
    "    female = df[(df['sex'] == 1)]\n",
    "    ratio_female = (female[female['confusion_matrix'] == 'FN'].shape[0] / \n",
    "        female[female['confusion_matrix'] == 'FP'].shape[0])\n",
    "\n",
    "    male = df[(df['sex'] == 0)]\n",
    "    ratio_male = (male[male['confusion_matrix'] == 'FN'].shape[0] / \n",
    "        male[male['confusion_matrix'] == 'FP'].shape[0])\n",
    "\n",
    "    print('Female Ratio of Errors: %.3f' % ratio_female)\n",
    "    print('Male Ratio of Errors: %.3f' % ratio_male)\n",
    "    \n",
    "    abs_difference = abs(ratio_female - ratio_male)\n",
    "    print('Achieves Treatment Equality: %r' % (abs_difference < threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9d43a913-fe5a-46f3-91da-e23cf72f6e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Female Probability of Positive Predictions: 0.043\n",
      "Male Probability of Positive Predictions: 0.036\n",
      "Achieves Statistical Parity: False\n",
      "Female Probability of True Positive Predictions: 0.572\n",
      "Male Probability of True Positive Predictions: 0.570\n",
      "Achieves Statistical Parity: False\n",
      "Probability of Credit-Worthy Female Predicted Not Credit-Worthy: 0.835\n",
      "Probability of Credit-Worthy Male Predicted Not Credit-Worthy: 0.842\n",
      "Achieves Equality of Non Credit Worthy Prediction: False\n",
      "Probability of Non Credit-Worthy Female Predicted Credit-Worthy: 0.022\n",
      "Probability of Non Credit-Worthy Male Predicted Credit-Worthy: 0.018\n",
      "Achieves Equality of Credit Worthy Prediction: False\n",
      "Female Accuracy: 0.857\n",
      "Male Accuracy: 0.876\n",
      "Equality of Accuracy: False\n",
      "Female Ratio of Errors: 6.795\n",
      "Male Ratio of Errors: 7.092\n",
      "Achieves Treatment Equality: False\n"
     ]
    }
   ],
   "source": [
    "statistical_parity(fair_df)\n",
    "predictive_parity(fair_df)\n",
    "equalized_odds(fair_df)\n",
    "accuracy_equality(fair_df)\n",
    "treatment_equality(fair_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8cf444-3048-4c54-87f2-e47ec29e5d11",
   "metadata": {},
   "source": [
    "## Mitigation through Post-Processiong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5790a4-6c42-41ca-b920-778d1d77fffa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
