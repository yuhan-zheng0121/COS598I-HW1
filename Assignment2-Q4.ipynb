{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "346a1ac8-cea4-4153-bd46-c65cb76532eb",
   "metadata": {},
   "source": [
    "source: https://archive.ics.uci.edu/dataset/891/cdc+diabetes+health+indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff0148eb-bf30-458a-afca-ba3a3dfd968e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "218f074f-87b9-4033-834a-910dd7acaa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict, RepeatedStratifiedKFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42a9fc8-4c7c-43e5-8137-1b757f1a71b4",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fec71d56-bdfa-45da-b17a-4a8acab9a708",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    # Load the dataset\n",
    "    cdc_diabetes_health_indicators = fetch_ucirepo(id=891) \n",
    "\n",
    "    # Define categorical and numerical features\n",
    "    categorical_features = ['HighBP', 'HighChol','CholCheck','Smoker','Stroke','HeartDiseaseorAttack',\n",
    "                            'PhysActivity','Fruits','Veggies','HvyAlcoholConsump','AnyHealthcare','NoDocbcCost','GenHlth',\n",
    "                            'DiffWalk','Sex','Age','Education','Income']\n",
    "    numerical_features = ['BMI','MentHlth','PhysHlth',]\n",
    "\n",
    "    # Get features and target variable\n",
    "    X = cdc_diabetes_health_indicators.data.features\n",
    "    y = cdc_diabetes_health_indicators.data.targets['Diabetes_binary'] \n",
    "\n",
    "    # Preprocessing: One-hot encoding for categorical variables and scaling for numerical variables\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numerical_features),\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "        ])\n",
    "\n",
    "    # Split the dataset into training and testing sets with a fixed random state for reproducibility\n",
    "    X_train_full, X_test_full, y_train, y_test, gender_train, gender_test = train_test_split(X, y, \n",
    "                                                                                             cdc_diabetes_health_indicators.data.features['Sex'],\n",
    "                                                                                             test_size=0.2, random_state=42)\n",
    "    # Apply preprocessing to training and testing set separately\n",
    "    X_train_processed = preprocessor.fit_transform(X_train_full)\n",
    "    X_test_processed = preprocessor.transform(X_test_full)\n",
    "\n",
    "    # Return processed training and testing sets along with gender attributes\n",
    "    return X_train_processed, X_test_processed, y_train, y_test, gender_train.values, gender_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95f22a21-81e1-40b1-88d3-a813fcbcd006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cdc_diabetes_health_indicators.metadata\n",
    "# cdc_diabetes_health_indicators.variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99af9e8c-5a5a-4ce2-8583-2c3fcdbc9fb5",
   "metadata": {},
   "source": [
    "## Train Model and Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d4c7f79-ec9b-4d69-bd26-0c400213e671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict_model(X_train, X_test, y_train, weights=None):\n",
    "\n",
    "    # Initialize the Logistic Regression model\n",
    "    model = LogisticRegression(max_iter=10000, random_state=0)\n",
    "\n",
    "    # Train the Logistic Regression model\n",
    "    model.fit(X_train, y_train, sample_weight=weights)\n",
    "\n",
    "    # Predict on the testing set\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)\n",
    "\n",
    "    return y_pred, y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17b27f41-f1e5-4207-b636-137f34451291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_confusion_matrix(df):\n",
    "    if df['y_true'] == df['y_pred'] == 1:\n",
    "        return 'TP'\n",
    "    elif df['y_pred'] == 1 and df['y_true'] != df['y_pred']:\n",
    "        return 'FP'\n",
    "    elif df['y_true'] == df['y_pred'] == 0:\n",
    "        return 'TN'\n",
    "    else:\n",
    "        return 'FN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be0e43e4-2f58-4737-8f0e-d6c07e988f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess and load the data\n",
    "X_train, X_test, y_train, y_test, gender_train, gender_test = load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d1760f-c9f1-4454-a059-695aa9e41cbe",
   "metadata": {},
   "source": [
    "### Select Model Based on Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5251fbe2-9d72-4716-b39e-57e6fe3efeee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8676285083569851 \n",
      "AUC: 0.8288682104560867 \n",
      "f1: 0.25111507582515613\n"
     ]
    }
   ],
   "source": [
    "# try logistic regression\n",
    "model1 = LogisticRegression(max_iter=10000, random_state=0)\n",
    "\n",
    "# Train the Logistic Regression model\n",
    "model1.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred1 = model1.predict(X_test)\n",
    "y_pred_proba1 = model1.predict_proba(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy1 = accuracy_score(y_test, y_pred1)\n",
    "auc1 = roc_auc_score(y_test, y_pred_proba1[:, 1])\n",
    "f1_1 = f1_score(y_test, y_pred1)\n",
    "\n",
    "print('Accuracy:', accuracy1, '\\nAUC:', auc1, '\\nf1:', f1_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a05e0cb4-d49e-4366-ad54-c186e4a4197c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8676876379690949 \n",
      "AUC: 0.8329001174326579 \n",
      "f1: 0.23323814962878356\n"
     ]
    }
   ],
   "source": [
    "# try nn\n",
    "model2 = MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(21,), random_state=1, max_iter=100)\n",
    "\n",
    "# Train the Logistic Regression model\n",
    "model2.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred2 = model2.predict(X_test)\n",
    "y_pred_proba2 = model2.predict_proba(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy2 = accuracy_score(y_test, y_pred2)\n",
    "auc2 = roc_auc_score(y_test, y_pred_proba2[:, 1])\n",
    "f1_2 = f1_score(y_test, y_pred2)\n",
    "\n",
    "print('Accuracy:', accuracy2, '\\nAUC:', auc2, '\\nf1:', f1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4855fad-564b-44f7-9078-0bbe302e726d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred1\n",
    "y_pred_proba = y_pred_proba1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2d83970-94b6-4ebd-88b3-78068e179577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>confusion_matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>219620</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132821</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151862</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139717</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239235</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sex  y_true  y_pred confusion_matrix\n",
       "219620    0       0       0               TN\n",
       "132821    0       0       0               TN\n",
       "151862    1       0       0               TN\n",
       "139717    1       0       0               TN\n",
       "239235    0       0       0               TN"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Female = 1 and Male = 0\n",
    "fair_df = pd.DataFrame({'sex': gender_test, 'y_true': y_test, 'y_pred': y_pred})\n",
    "fair_df['confusion_matrix'] = fair_df[['y_true','y_pred']].apply(determine_confusion_matrix, axis=1)\n",
    "fair_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b49c862-f0cc-4ac1-bfd5-3474a181aab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.94368563, 0.05631437],\n",
       "       [0.77818335, 0.22181665],\n",
       "       [0.99647578, 0.00352422],\n",
       "       ...,\n",
       "       [0.91103087, 0.08896913],\n",
       "       [0.86490401, 0.13509599],\n",
       "       [0.98639281, 0.01360719]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15b35201-c990-41e9-a8e7-189bdebdf0f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sex\n",
       "0    28412\n",
       "1    22324\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 stand for female and 0 is male\n",
    "fair_df['sex'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c5649a-647d-457b-85a3-ea5d15006b7d",
   "metadata": {},
   "source": [
    "## Fairness Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c691447-0c41-4d6d-b116-ec72af1e1c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6903f98d-f05e-4f21-bdf9-2418f7cc4d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistical_parity(df):\n",
    "    \"\"\"\n",
    "    TODO: Add your code here\n",
    "    \"\"\"\n",
    "    female_positive = df[(df['sex'] == 1) & (df['y_pred'] == 1)].shape[0]\n",
    "    female_positive_prob = female_positive / (df[(df['sex'] == 1)].shape[0])\n",
    "    \n",
    "    male_positive = df[(df['sex'] == 0) & (df['y_pred'] == 1)].shape[0]\n",
    "    male_positive_prob = male_positive / (df[(df['sex'] == 0)].shape[0])\n",
    "\n",
    "    print('Female Probability of Positive Predictions: %.3f' % female_positive_prob)\n",
    "    print('Male Probability of Positive Predictions: %.3f' % male_positive_prob)\n",
    "    \n",
    "    abs_difference = abs(female_positive_prob - male_positive_prob)\n",
    "    print('Achieves Statistical Parity: %r' % (abs_difference < threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de79c959-16b5-4178-b962-eec1f1c5e6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictive_parity(df):\n",
    "    \"\"\"\n",
    "    TODO: Add your code here\n",
    "    \"\"\"\n",
    "    female_TP = df[(df['sex'] == 1) & (df['confusion_matrix'] == 'TP')].shape[0]\n",
    "    PPV_female = female_TP / (df[(df['sex'] == 1) & (df['y_pred'] == 1)].shape[0])\n",
    "    \n",
    "    male_TP = df[(df['sex'] == 0) & (df['confusion_matrix'] == 'TP')].shape[0]\n",
    "    PPV_male = male_TP / (df[(df['sex'] == 0) & (df['y_pred'] == 1)].shape[0])\n",
    "\n",
    "    print('Female Probability of True Positive Predictions: %.3f' % PPV_female)\n",
    "    print('Male Probability of True Positive Predictions: %.3f' % PPV_male)\n",
    "    \n",
    "    abs_difference = abs(PPV_female - PPV_male)\n",
    "    print('Achieves Statistical Parity: %r' % (abs_difference < threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3bcc00d-7793-4991-8929-bcc303d76957",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equalized_odds(df):\n",
    "    \"\"\"\n",
    "    TODO: Add your code here\n",
    "    \"\"\"\n",
    "    # FNR = FN/(FN+TP) = FN/(all-positive-true-label)\n",
    "    female_fn = df[(df['sex'] == 1) & (df['confusion_matrix'] == 'FN')].shape[0]\n",
    "    fnr_female = female_fn / (df[(df['sex'] == 1) & (df['y_true'] == 1)].shape[0])\n",
    "    male_fn = df[(df['sex'] == 0) & (df['confusion_matrix'] == 'FN')].shape[0]\n",
    "    fnr_male = male_fn / (df[(df['sex'] == 0) & (df['y_true'] == 1)].shape[0])\n",
    "    \n",
    "    # FPR = FP/(FP+TN) = FN/(all-negative-true-label)\n",
    "    female_fp = df[(df['sex'] == 1) & (df['confusion_matrix'] == 'FP')].shape[0]\n",
    "    fpr_female = female_fp / (df[(df['sex'] == 1) & (df['y_true'] == 0)].shape[0])\n",
    "    male_fp = df[(df['sex'] == 0) & (df['confusion_matrix'] == 'FP')].shape[0]\n",
    "    fpr_male = male_fp / (df[(df['sex'] == 0) & (df['y_true'] == 0)].shape[0])\n",
    "\n",
    "    print('Probability of Credit-Worthy Female Predicted Not Credit-Worthy: %.3f' % fnr_female)\n",
    "    print('Probability of Credit-Worthy Male Predicted Not Credit-Worthy: %.3f' % fnr_male)\n",
    "    \n",
    "    abs_difference_fnr = abs(fnr_female - fnr_male)\n",
    "    print('Achieves Equality of Non Credit Worthy Prediction: %r' % (abs_difference_fnr < threshold))\n",
    "    \n",
    "    print('Probability of Non Credit-Worthy Female Predicted Credit-Worthy: %.3f' % fpr_female)\n",
    "    print('Probability of Non Credit-Worthy Male Predicted Credit-Worthy: %.3f' % fpr_male)\n",
    "    \n",
    "    abs_difference_fpr = abs(fnr_female - fnr_male)\n",
    "    print('Achieves Equality of Credit Worthy Prediction: %r' % (abs_difference_fpr < threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8462a21d-b449-4449-b5c2-d4b664d914b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_equality(df):\n",
    "    \"\"\"\n",
    "    TODO: Add your code here\n",
    "    \"\"\"\n",
    "\n",
    "    # Accuracy = (TP+TN)/all-samples\n",
    "    female_t = df[(df['sex'] == 1) & (df['confusion_matrix'].isin(['TP', 'TN']))].shape[0]\n",
    "    accuracy_female = female_t / (df[(df['sex'] == 1)].shape[0])\n",
    "    male_t = df[(df['sex'] == 0) & (df['confusion_matrix'].isin(['TP', 'TN']))].shape[0]\n",
    "    accuracy_male = male_t / (df[(df['sex'] == 0)].shape[0])\n",
    "    \n",
    "    print('Female Accuracy: %.3f' % accuracy_female)\n",
    "    print('Male Accuracy: %.3f' % accuracy_male)\n",
    "    \n",
    "    abs_difference = abs(accuracy_female - accuracy_male)\n",
    "    print('Equality of Accuracy: %r' % (abs_difference < threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c44e558-3bfb-4681-8d1b-bc85e33c8785",
   "metadata": {},
   "outputs": [],
   "source": [
    "def treatment_equality(df):\n",
    "    \"\"\"\n",
    "    TODO: Add your code here\n",
    "    \"\"\"\n",
    "    \n",
    "    female = df[(df['sex'] == 1)]\n",
    "    ratio_female = (female[female['confusion_matrix'] == 'FN'].shape[0] / \n",
    "        female[female['confusion_matrix'] == 'FP'].shape[0])\n",
    "\n",
    "    male = df[(df['sex'] == 0)]\n",
    "    ratio_male = (male[male['confusion_matrix'] == 'FN'].shape[0] / \n",
    "        male[male['confusion_matrix'] == 'FP'].shape[0])\n",
    "\n",
    "    print('Female Ratio of Errors: %.3f' % ratio_female)\n",
    "    print('Male Ratio of Errors: %.3f' % ratio_male)\n",
    "    \n",
    "    abs_difference = abs(ratio_female - ratio_male)\n",
    "    print('Achieves Treatment Equality: %r' % (abs_difference < threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d43a913-fe5a-46f3-91da-e23cf72f6e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Female Probability of Positive Predictions: 0.043\n",
      "Male Probability of Positive Predictions: 0.036\n",
      "Achieves Statistical Parity: False\n",
      "Female Probability of True Positive Predictions: 0.572\n",
      "Male Probability of True Positive Predictions: 0.570\n",
      "Achieves Statistical Parity: False\n",
      "Probability of Credit-Worthy Female Predicted Not Credit-Worthy: 0.835\n",
      "Probability of Credit-Worthy Male Predicted Not Credit-Worthy: 0.842\n",
      "Achieves Equality of Non Credit Worthy Prediction: False\n",
      "Probability of Non Credit-Worthy Female Predicted Credit-Worthy: 0.022\n",
      "Probability of Non Credit-Worthy Male Predicted Credit-Worthy: 0.018\n",
      "Achieves Equality of Credit Worthy Prediction: False\n",
      "Female Accuracy: 0.857\n",
      "Male Accuracy: 0.876\n",
      "Equality of Accuracy: False\n",
      "Female Ratio of Errors: 6.795\n",
      "Male Ratio of Errors: 7.092\n",
      "Achieves Treatment Equality: False\n"
     ]
    }
   ],
   "source": [
    "statistical_parity(fair_df)\n",
    "predictive_parity(fair_df)\n",
    "equalized_odds(fair_df)\n",
    "accuracy_equality(fair_df)\n",
    "treatment_equality(fair_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8cf444-3048-4c54-87f2-e47ec29e5d11",
   "metadata": {},
   "source": [
    "## Mitigation through Post-Processiong"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51c8ff3-6aae-4bc9-810e-f10e8a022e97",
   "metadata": {},
   "source": [
    "On Fairness and Calibration: https://arxiv.org/pdf/1709.02012.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0eb87045-7346-4d10-b2f4-b5e86e827c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate trivial classifier output\n",
    "def get_trivial_pred(df):\n",
    "    trivial_pred = df['y_true'].mean()\n",
    "    trivial_df = df.assign(y_prob_1=[trivial_pred]*df.shape[0])\n",
    "    trivial_df = reclassify(trivial_df)\n",
    "    \n",
    "    return trivial_df, trivial_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5937d060-9729-4bf5-8080-e13d60b2d889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reassign prediction based on the adjusted y_prob(args_max)\n",
    "def reclassify(df): \n",
    "    new_y_pred = []\n",
    "    for _, row in df.iterrows():\n",
    "        if row['y_prob_0'] >=  row['y_prob_1']:\n",
    "            new_y_pred .append(0)\n",
    "        else:\n",
    "            new_y_pred .append(1)\n",
    "    df['y_pred'] = new_y_pred \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32e703cc-3025-42c2-ba43-9e0748c23a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute fpr and fnr given y_probs and true labels\n",
    "def compute_errors(df):\n",
    "    df['confusion_matrix'] = df[['y_true','y_pred']].apply(determine_confusion_matrix, axis=1)\n",
    "    fpr = df[df['confusion_matrix'] == 'FP'].shape[0]/df[df['y_true'] == 0].shape[0]\n",
    "    fnr = df[df['confusion_matrix'] == 'FN'].shape[0]/df[df['y_true'] == 1].shape[0]\n",
    "    return fpr, fnr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9c5790a4-6c42-41ca-b920-778d1d77fffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibrate \n",
    "def calib_eq_odds(g1_val, g2_val, g1, g2, fnr=1, fpr=1):\n",
    "    g1_val_prob = g1_val.drop(columns=['y_pred'])\n",
    "    g2_val_prob = g2_val.drop(columns=['y_pred'])\n",
    "\n",
    "    # simluate trivial classifier with holdout data\n",
    "    g1_trivial, g1_trivial_pred = get_trivial_pred(g1_val_prob)\n",
    "    g2_trivial, g2_trivial_pred  = get_trivial_pred(g2_val_prob)\n",
    "\n",
    "    # compute fpr and fnr for all 4 sets of output\n",
    "    g1_fpr, g1_fnr = compute_errors(g1)\n",
    "    g1_trivial_fpr, g1_trivial_fnr  = compute_errors(g1_trivial)\n",
    "    g2_fpr, g2_fnr = compute_errors(g2)\n",
    "    g2_trivial_fpr, g2_trivial_fnr  = compute_errors(g2_trivial)\n",
    "\n",
    "    # compute generalized fpr and generalized fnr for all 4 sets of output\n",
    "    g1_g_fp = g1.loc[g1['y_true'] == 0, 'y_prob_1'].mean() # g1_fp_cost = mean y_pred=1 prob for rows where y_true=0\n",
    "    g2_g_fp = g2.loc[g2['y_true'] == 0, 'y_prob_1'].mean()\n",
    "    g1_trivial_g_fp = g1_trivial.loc[g1_trivial['y_true'] == 0, 'y_prob_1'].mean()\n",
    "    g2_trivial_g_fp = g2_trivial.loc[g2_trivial['y_true'] == 0, 'y_prob_1'].mean()\n",
    "    g1_g_fn = g1.loc[g1['y_true'] == 0, 'y_prob_1'].mean() # g1_fp_cost = mean y_pred=1 prob for rows where y_true=0\n",
    "    g2_g_fn = g2.loc[g2['y_true'] == 0, 'y_prob_1'].mean()\n",
    "    g1_trivial_g_fn = g1_trivial.loc[g1_trivial['y_true'] == 0, 'y_prob_1'].mean()\n",
    "    g2_trivial_g_fn = g2_trivial.loc[g2_trivial['y_true'] == 0, 'y_prob_1'].mean()\n",
    "\n",
    "    # calibrate FP rate\n",
    "    if fpr:\n",
    "        g1_cost = g1_g_fp\n",
    "        g2_cost = g2_g_fp\n",
    "        g1_trivial_cost = g1_trivial_g_fp\n",
    "        g2_trivial_cost = g2_trivial_g_fp\n",
    "    # calibrate FN rate\n",
    "    elif fnr:\n",
    "        g1_cost = g1_g_fn\n",
    "        g2_cost = g2_g_fn\n",
    "        g1_trivial_cost = g1_trivial_g_fn\n",
    "        g2_trivial_cost = g2_trivial_g_fn\n",
    "    # consider both\n",
    "    else:\n",
    "        g1_cost = g1_fpr / 2.0 * g1_g_fp * (1 - g1_trivial_pred) + g1_fnr / 2.0 * g1_g_fn * g1_trivial_pred\n",
    "        g2_cost = g2_fpr / 2.0 * g2_g_fp * (1 - g2_trivial_pred) + g2_fnr / 2.0 * g2_g_fn * g1_trivial_pred\n",
    "        g1_trivial_cost = g1_trivial_fpr / 2.0 * g1_trivial_g_fp * (1 - g2_trivial_pred) + g2_fnr / 2.0 * g1_trivial_g_fn * g1_trivial_pred\n",
    "        g2_trivial_cost = g2_trivial_fpr / 2.0 * g2_trivial_g_fp * (1 - g2_trivial_pred) + g2_fnr / 2.0 * g2_trivial_g_fn * g1_trivial_pred\n",
    "\n",
    "    # determine what % of preditions need to be calibrated\n",
    "    g1_mix_rate = (g2_cost - g1_cost) / (g1_trivial_cost - g1_cost) if g2_cost > g1_cost else 0\n",
    "    g2_mix_rate = (g1_cost - g2_cost) / (g2_trivial_cost - g2_cost) if g1_cost > g2_cost else 0\n",
    "    \n",
    "    # Randomly select mix_rate% of elements from the prediction\n",
    "    g1_copy = g1.copy(deep=True)\n",
    "    g1_random_indices = np.random.choice(g1_copy['y_prob_1'].index, size=int(g1_mix_rate*g1_copy.shape[0]), replace=False)\n",
    "    g2_copy = g2.copy(deep=True)\n",
    "    g2_random_indices = np.random.choice(g2_copy['y_prob_1'].index, size=int(g2_mix_rate*g2_copy.shape[0]), replace=False)\n",
    "    # Set those to base_rate\n",
    "    g1_copy.loc[g1_random_indices, 'y_prob_1'] = g1_trivial_pred\n",
    "    g2_copy.loc[g2_random_indices, 'y_prob_1'] = g2_trivial_pred\n",
    "    # reclassify\n",
    "    caibrated_g1 = reclassify(g1_copy)\n",
    "    caibrated_g2 = reclassify(g2_copy)\n",
    "    # Update confusion matrix\n",
    "    caibrated_g1['confusion_matrix'] = caibrated_g1[['y_true','y_pred']].apply(determine_confusion_matrix, axis=1)\n",
    "    caibrated_g2['confusion_matrix'] = caibrated_g2[['y_true','y_pred']].apply(determine_confusion_matrix, axis=1)\n",
    "\n",
    "    return caibrated_g1, caibrated_g2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1605191a-360e-4700-87ab-c9a09c33398c",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_processiong_df = pd.DataFrame({'sex': gender_test, 'y_true': y_test, 'y_pred': y_pred, 'y_prob_1': y_pred_proba[:, 1], 'y_prob_0': y_pred_proba[:, 0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dd72964b-bcb4-4bf8-8b74-e9e5154e2e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred\n",
      "0    13727\n",
      "1      471\n",
      "Name: count, dtype: int64 0.13092837124167578\n",
      "y_pred\n",
      "0    10688\n",
      "1      482\n",
      "Name: count, dtype: int64 0.15296408167591213\n"
     ]
    }
   ],
   "source": [
    "val_data, test_data = train_test_split(post_processiong_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# Create model objects - one for each group, validation and test\n",
    "male_val_data = val_data[val_data['sex'] == 0]\n",
    "female_val_data = val_data[val_data['sex'] == 1]\n",
    "male_test_data = test_data[test_data['sex'] == 0]\n",
    "print(male_test_data['y_pred'].value_counts(), male_test_data['y_prob_1'].mean())\n",
    "female_test_data = test_data[test_data['sex'] == 1]\n",
    "print(female_test_data['y_pred'].value_counts(), female_test_data['y_prob_1'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5d3192de-0d76-4711-a6fa-b0639f12e2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/19/_f2tmq1s35s0sxc12yzg4mc00000gn/T/ipykernel_97570/2749376926.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['confusion_matrix'] = df[['y_true','y_pred']].apply(determine_confusion_matrix, axis=1)\n",
      "/var/folders/19/_f2tmq1s35s0sxc12yzg4mc00000gn/T/ipykernel_97570/2749376926.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['confusion_matrix'] = df[['y_true','y_pred']].apply(determine_confusion_matrix, axis=1)\n"
     ]
    }
   ],
   "source": [
    "calibrated_g1, calibrated_g2 = calib_eq_odds(male_val_data, female_val_data, male_test_data, female_test_data, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0a165153-d5e2-45d2-bdf8-437c5266ebe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred\n",
      "0    14071\n",
      "1      127\n",
      "Name: count, dtype: int64 0.13161768014699238\n",
      "y_pred\n",
      "0    10688\n",
      "1      482\n",
      "Name: count, dtype: int64 0.15296408167591213\n"
     ]
    }
   ],
   "source": [
    "print(calibrated_g1['y_pred'].value_counts(), calibrated_g1['y_prob_1'].mean())\n",
    "print(calibrated_g2['y_pred'].value_counts(), calibrated_g2['y_prob_1'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a0d5b81b-81ea-44c7-b1b1-027dbfba9071",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrated = pd.concat([calibrated_g1, calibrated_g2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fa1ac633-4045-4b56-b5b2-4a3caec5f87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Female Probability of Positive Predictions: 0.043\n",
      "Male Probability of Positive Predictions: 0.009\n",
      "Achieves Statistical Parity: False\n",
      "Female Probability of True Positive Predictions: 0.591\n",
      "Male Probability of True Positive Predictions: 0.528\n",
      "Achieves Statistical Parity: False\n",
      "Probability of Credit-Worthy Female Predicted Not Credit-Worthy: 0.831\n",
      "Probability of Credit-Worthy Male Predicted Not Credit-Worthy: 0.963\n",
      "Achieves Equality of Non Credit Worthy Prediction: False\n",
      "Probability of Non Credit-Worthy Female Predicted Credit-Worthy: 0.021\n",
      "Probability of Non Credit-Worthy Male Predicted Credit-Worthy: 0.005\n",
      "Achieves Equality of Credit Worthy Prediction: False\n",
      "Female Accuracy: 0.857\n",
      "Male Accuracy: 0.874\n",
      "Equality of Accuracy: False\n",
      "Female Ratio of Errors: 7.091\n",
      "Male Ratio of Errors: 28.917\n",
      "Achieves Treatment Equality: False\n"
     ]
    }
   ],
   "source": [
    "statistical_parity(calibrated)\n",
    "predictive_parity(calibrated)\n",
    "equalized_odds(calibrated)\n",
    "accuracy_equality(calibrated)\n",
    "treatment_equality(calibrated)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
